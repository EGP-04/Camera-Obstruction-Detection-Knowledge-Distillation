{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd3c71a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchvision.models import efficientnet_b0\n",
    "\n",
    "class BinaryEfficientNet(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(BinaryEfficientNet, self).__init__()\n",
    "        \n",
    "        # Load pre-trained EfficientNet-B0\n",
    "        self.base_model = efficientnet_b0(pretrained=pretrained)\n",
    "        \n",
    "        # Get number of features in the final layer\n",
    "        num_features = self.base_model.classifier[1].in_features\n",
    "        \n",
    "        # Replace the classifier with a binary classifier\n",
    "        self.base_model.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.2, inplace=True),\n",
    "            nn.Linear(num_features, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.base_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e1ba96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 112, 112]             864\n",
      "       BatchNorm2d-2         [-1, 32, 112, 112]              64\n",
      "              SiLU-3         [-1, 32, 112, 112]               0\n",
      "            Conv2d-4         [-1, 32, 112, 112]             288\n",
      "       BatchNorm2d-5         [-1, 32, 112, 112]              64\n",
      "              SiLU-6         [-1, 32, 112, 112]               0\n",
      " AdaptiveAvgPool2d-7             [-1, 32, 1, 1]               0\n",
      "            Conv2d-8              [-1, 8, 1, 1]             264\n",
      "              SiLU-9              [-1, 8, 1, 1]               0\n",
      "           Conv2d-10             [-1, 32, 1, 1]             288\n",
      "          Sigmoid-11             [-1, 32, 1, 1]               0\n",
      "SqueezeExcitation-12         [-1, 32, 112, 112]               0\n",
      "           Conv2d-13         [-1, 16, 112, 112]             512\n",
      "      BatchNorm2d-14         [-1, 16, 112, 112]              32\n",
      "           MBConv-15         [-1, 16, 112, 112]               0\n",
      "           Conv2d-16         [-1, 96, 112, 112]           1,536\n",
      "      BatchNorm2d-17         [-1, 96, 112, 112]             192\n",
      "             SiLU-18         [-1, 96, 112, 112]               0\n",
      "           Conv2d-19           [-1, 96, 56, 56]             864\n",
      "      BatchNorm2d-20           [-1, 96, 56, 56]             192\n",
      "             SiLU-21           [-1, 96, 56, 56]               0\n",
      "AdaptiveAvgPool2d-22             [-1, 96, 1, 1]               0\n",
      "           Conv2d-23              [-1, 4, 1, 1]             388\n",
      "             SiLU-24              [-1, 4, 1, 1]               0\n",
      "           Conv2d-25             [-1, 96, 1, 1]             480\n",
      "          Sigmoid-26             [-1, 96, 1, 1]               0\n",
      "SqueezeExcitation-27           [-1, 96, 56, 56]               0\n",
      "           Conv2d-28           [-1, 24, 56, 56]           2,304\n",
      "      BatchNorm2d-29           [-1, 24, 56, 56]              48\n",
      "           MBConv-30           [-1, 24, 56, 56]               0\n",
      "           Conv2d-31          [-1, 144, 56, 56]           3,456\n",
      "      BatchNorm2d-32          [-1, 144, 56, 56]             288\n",
      "             SiLU-33          [-1, 144, 56, 56]               0\n",
      "           Conv2d-34          [-1, 144, 56, 56]           1,296\n",
      "      BatchNorm2d-35          [-1, 144, 56, 56]             288\n",
      "             SiLU-36          [-1, 144, 56, 56]               0\n",
      "AdaptiveAvgPool2d-37            [-1, 144, 1, 1]               0\n",
      "           Conv2d-38              [-1, 6, 1, 1]             870\n",
      "             SiLU-39              [-1, 6, 1, 1]               0\n",
      "           Conv2d-40            [-1, 144, 1, 1]           1,008\n",
      "          Sigmoid-41            [-1, 144, 1, 1]               0\n",
      "SqueezeExcitation-42          [-1, 144, 56, 56]               0\n",
      "           Conv2d-43           [-1, 24, 56, 56]           3,456\n",
      "      BatchNorm2d-44           [-1, 24, 56, 56]              48\n",
      "  StochasticDepth-45           [-1, 24, 56, 56]               0\n",
      "           MBConv-46           [-1, 24, 56, 56]               0\n",
      "           Conv2d-47          [-1, 144, 56, 56]           3,456\n",
      "      BatchNorm2d-48          [-1, 144, 56, 56]             288\n",
      "             SiLU-49          [-1, 144, 56, 56]               0\n",
      "           Conv2d-50          [-1, 144, 28, 28]           3,600\n",
      "      BatchNorm2d-51          [-1, 144, 28, 28]             288\n",
      "             SiLU-52          [-1, 144, 28, 28]               0\n",
      "AdaptiveAvgPool2d-53            [-1, 144, 1, 1]               0\n",
      "           Conv2d-54              [-1, 6, 1, 1]             870\n",
      "             SiLU-55              [-1, 6, 1, 1]               0\n",
      "           Conv2d-56            [-1, 144, 1, 1]           1,008\n",
      "          Sigmoid-57            [-1, 144, 1, 1]               0\n",
      "SqueezeExcitation-58          [-1, 144, 28, 28]               0\n",
      "           Conv2d-59           [-1, 40, 28, 28]           5,760\n",
      "      BatchNorm2d-60           [-1, 40, 28, 28]              80\n",
      "           MBConv-61           [-1, 40, 28, 28]               0\n",
      "           Conv2d-62          [-1, 240, 28, 28]           9,600\n",
      "      BatchNorm2d-63          [-1, 240, 28, 28]             480\n",
      "             SiLU-64          [-1, 240, 28, 28]               0\n",
      "           Conv2d-65          [-1, 240, 28, 28]           6,000\n",
      "      BatchNorm2d-66          [-1, 240, 28, 28]             480\n",
      "             SiLU-67          [-1, 240, 28, 28]               0\n",
      "AdaptiveAvgPool2d-68            [-1, 240, 1, 1]               0\n",
      "           Conv2d-69             [-1, 10, 1, 1]           2,410\n",
      "             SiLU-70             [-1, 10, 1, 1]               0\n",
      "           Conv2d-71            [-1, 240, 1, 1]           2,640\n",
      "          Sigmoid-72            [-1, 240, 1, 1]               0\n",
      "SqueezeExcitation-73          [-1, 240, 28, 28]               0\n",
      "           Conv2d-74           [-1, 40, 28, 28]           9,600\n",
      "      BatchNorm2d-75           [-1, 40, 28, 28]              80\n",
      "  StochasticDepth-76           [-1, 40, 28, 28]               0\n",
      "           MBConv-77           [-1, 40, 28, 28]               0\n",
      "           Conv2d-78          [-1, 240, 28, 28]           9,600\n",
      "      BatchNorm2d-79          [-1, 240, 28, 28]             480\n",
      "             SiLU-80          [-1, 240, 28, 28]               0\n",
      "           Conv2d-81          [-1, 240, 14, 14]           2,160\n",
      "      BatchNorm2d-82          [-1, 240, 14, 14]             480\n",
      "             SiLU-83          [-1, 240, 14, 14]               0\n",
      "AdaptiveAvgPool2d-84            [-1, 240, 1, 1]               0\n",
      "           Conv2d-85             [-1, 10, 1, 1]           2,410\n",
      "             SiLU-86             [-1, 10, 1, 1]               0\n",
      "           Conv2d-87            [-1, 240, 1, 1]           2,640\n",
      "          Sigmoid-88            [-1, 240, 1, 1]               0\n",
      "SqueezeExcitation-89          [-1, 240, 14, 14]               0\n",
      "           Conv2d-90           [-1, 80, 14, 14]          19,200\n",
      "      BatchNorm2d-91           [-1, 80, 14, 14]             160\n",
      "           MBConv-92           [-1, 80, 14, 14]               0\n",
      "           Conv2d-93          [-1, 480, 14, 14]          38,400\n",
      "      BatchNorm2d-94          [-1, 480, 14, 14]             960\n",
      "             SiLU-95          [-1, 480, 14, 14]               0\n",
      "           Conv2d-96          [-1, 480, 14, 14]           4,320\n",
      "      BatchNorm2d-97          [-1, 480, 14, 14]             960\n",
      "             SiLU-98          [-1, 480, 14, 14]               0\n",
      "AdaptiveAvgPool2d-99            [-1, 480, 1, 1]               0\n",
      "          Conv2d-100             [-1, 20, 1, 1]           9,620\n",
      "            SiLU-101             [-1, 20, 1, 1]               0\n",
      "          Conv2d-102            [-1, 480, 1, 1]          10,080\n",
      "         Sigmoid-103            [-1, 480, 1, 1]               0\n",
      "SqueezeExcitation-104          [-1, 480, 14, 14]               0\n",
      "          Conv2d-105           [-1, 80, 14, 14]          38,400\n",
      "     BatchNorm2d-106           [-1, 80, 14, 14]             160\n",
      " StochasticDepth-107           [-1, 80, 14, 14]               0\n",
      "          MBConv-108           [-1, 80, 14, 14]               0\n",
      "          Conv2d-109          [-1, 480, 14, 14]          38,400\n",
      "     BatchNorm2d-110          [-1, 480, 14, 14]             960\n",
      "            SiLU-111          [-1, 480, 14, 14]               0\n",
      "          Conv2d-112          [-1, 480, 14, 14]           4,320\n",
      "     BatchNorm2d-113          [-1, 480, 14, 14]             960\n",
      "            SiLU-114          [-1, 480, 14, 14]               0\n",
      "AdaptiveAvgPool2d-115            [-1, 480, 1, 1]               0\n",
      "          Conv2d-116             [-1, 20, 1, 1]           9,620\n",
      "            SiLU-117             [-1, 20, 1, 1]               0\n",
      "          Conv2d-118            [-1, 480, 1, 1]          10,080\n",
      "         Sigmoid-119            [-1, 480, 1, 1]               0\n",
      "SqueezeExcitation-120          [-1, 480, 14, 14]               0\n",
      "          Conv2d-121           [-1, 80, 14, 14]          38,400\n",
      "     BatchNorm2d-122           [-1, 80, 14, 14]             160\n",
      " StochasticDepth-123           [-1, 80, 14, 14]               0\n",
      "          MBConv-124           [-1, 80, 14, 14]               0\n",
      "          Conv2d-125          [-1, 480, 14, 14]          38,400\n",
      "     BatchNorm2d-126          [-1, 480, 14, 14]             960\n",
      "            SiLU-127          [-1, 480, 14, 14]               0\n",
      "          Conv2d-128          [-1, 480, 14, 14]          12,000\n",
      "     BatchNorm2d-129          [-1, 480, 14, 14]             960\n",
      "            SiLU-130          [-1, 480, 14, 14]               0\n",
      "AdaptiveAvgPool2d-131            [-1, 480, 1, 1]               0\n",
      "          Conv2d-132             [-1, 20, 1, 1]           9,620\n",
      "            SiLU-133             [-1, 20, 1, 1]               0\n",
      "          Conv2d-134            [-1, 480, 1, 1]          10,080\n",
      "         Sigmoid-135            [-1, 480, 1, 1]               0\n",
      "SqueezeExcitation-136          [-1, 480, 14, 14]               0\n",
      "          Conv2d-137          [-1, 112, 14, 14]          53,760\n",
      "     BatchNorm2d-138          [-1, 112, 14, 14]             224\n",
      "          MBConv-139          [-1, 112, 14, 14]               0\n",
      "          Conv2d-140          [-1, 672, 14, 14]          75,264\n",
      "     BatchNorm2d-141          [-1, 672, 14, 14]           1,344\n",
      "            SiLU-142          [-1, 672, 14, 14]               0\n",
      "          Conv2d-143          [-1, 672, 14, 14]          16,800\n",
      "     BatchNorm2d-144          [-1, 672, 14, 14]           1,344\n",
      "            SiLU-145          [-1, 672, 14, 14]               0\n",
      "AdaptiveAvgPool2d-146            [-1, 672, 1, 1]               0\n",
      "          Conv2d-147             [-1, 28, 1, 1]          18,844\n",
      "            SiLU-148             [-1, 28, 1, 1]               0\n",
      "          Conv2d-149            [-1, 672, 1, 1]          19,488\n",
      "         Sigmoid-150            [-1, 672, 1, 1]               0\n",
      "SqueezeExcitation-151          [-1, 672, 14, 14]               0\n",
      "          Conv2d-152          [-1, 112, 14, 14]          75,264\n",
      "     BatchNorm2d-153          [-1, 112, 14, 14]             224\n",
      " StochasticDepth-154          [-1, 112, 14, 14]               0\n",
      "          MBConv-155          [-1, 112, 14, 14]               0\n",
      "          Conv2d-156          [-1, 672, 14, 14]          75,264\n",
      "     BatchNorm2d-157          [-1, 672, 14, 14]           1,344\n",
      "            SiLU-158          [-1, 672, 14, 14]               0\n",
      "          Conv2d-159          [-1, 672, 14, 14]          16,800\n",
      "     BatchNorm2d-160          [-1, 672, 14, 14]           1,344\n",
      "            SiLU-161          [-1, 672, 14, 14]               0\n",
      "AdaptiveAvgPool2d-162            [-1, 672, 1, 1]               0\n",
      "          Conv2d-163             [-1, 28, 1, 1]          18,844\n",
      "            SiLU-164             [-1, 28, 1, 1]               0\n",
      "          Conv2d-165            [-1, 672, 1, 1]          19,488\n",
      "         Sigmoid-166            [-1, 672, 1, 1]               0\n",
      "SqueezeExcitation-167          [-1, 672, 14, 14]               0\n",
      "          Conv2d-168          [-1, 112, 14, 14]          75,264\n",
      "     BatchNorm2d-169          [-1, 112, 14, 14]             224\n",
      " StochasticDepth-170          [-1, 112, 14, 14]               0\n",
      "          MBConv-171          [-1, 112, 14, 14]               0\n",
      "          Conv2d-172          [-1, 672, 14, 14]          75,264\n",
      "     BatchNorm2d-173          [-1, 672, 14, 14]           1,344\n",
      "            SiLU-174          [-1, 672, 14, 14]               0\n",
      "          Conv2d-175            [-1, 672, 7, 7]          16,800\n",
      "     BatchNorm2d-176            [-1, 672, 7, 7]           1,344\n",
      "            SiLU-177            [-1, 672, 7, 7]               0\n",
      "AdaptiveAvgPool2d-178            [-1, 672, 1, 1]               0\n",
      "          Conv2d-179             [-1, 28, 1, 1]          18,844\n",
      "            SiLU-180             [-1, 28, 1, 1]               0\n",
      "          Conv2d-181            [-1, 672, 1, 1]          19,488\n",
      "         Sigmoid-182            [-1, 672, 1, 1]               0\n",
      "SqueezeExcitation-183            [-1, 672, 7, 7]               0\n",
      "          Conv2d-184            [-1, 192, 7, 7]         129,024\n",
      "     BatchNorm2d-185            [-1, 192, 7, 7]             384\n",
      "          MBConv-186            [-1, 192, 7, 7]               0\n",
      "          Conv2d-187           [-1, 1152, 7, 7]         221,184\n",
      "     BatchNorm2d-188           [-1, 1152, 7, 7]           2,304\n",
      "            SiLU-189           [-1, 1152, 7, 7]               0\n",
      "          Conv2d-190           [-1, 1152, 7, 7]          28,800\n",
      "     BatchNorm2d-191           [-1, 1152, 7, 7]           2,304\n",
      "            SiLU-192           [-1, 1152, 7, 7]               0\n",
      "AdaptiveAvgPool2d-193           [-1, 1152, 1, 1]               0\n",
      "          Conv2d-194             [-1, 48, 1, 1]          55,344\n",
      "            SiLU-195             [-1, 48, 1, 1]               0\n",
      "          Conv2d-196           [-1, 1152, 1, 1]          56,448\n",
      "         Sigmoid-197           [-1, 1152, 1, 1]               0\n",
      "SqueezeExcitation-198           [-1, 1152, 7, 7]               0\n",
      "          Conv2d-199            [-1, 192, 7, 7]         221,184\n",
      "     BatchNorm2d-200            [-1, 192, 7, 7]             384\n",
      " StochasticDepth-201            [-1, 192, 7, 7]               0\n",
      "          MBConv-202            [-1, 192, 7, 7]               0\n",
      "          Conv2d-203           [-1, 1152, 7, 7]         221,184\n",
      "     BatchNorm2d-204           [-1, 1152, 7, 7]           2,304\n",
      "            SiLU-205           [-1, 1152, 7, 7]               0\n",
      "          Conv2d-206           [-1, 1152, 7, 7]          28,800\n",
      "     BatchNorm2d-207           [-1, 1152, 7, 7]           2,304\n",
      "            SiLU-208           [-1, 1152, 7, 7]               0\n",
      "AdaptiveAvgPool2d-209           [-1, 1152, 1, 1]               0\n",
      "          Conv2d-210             [-1, 48, 1, 1]          55,344\n",
      "            SiLU-211             [-1, 48, 1, 1]               0\n",
      "          Conv2d-212           [-1, 1152, 1, 1]          56,448\n",
      "         Sigmoid-213           [-1, 1152, 1, 1]               0\n",
      "SqueezeExcitation-214           [-1, 1152, 7, 7]               0\n",
      "          Conv2d-215            [-1, 192, 7, 7]         221,184\n",
      "     BatchNorm2d-216            [-1, 192, 7, 7]             384\n",
      " StochasticDepth-217            [-1, 192, 7, 7]               0\n",
      "          MBConv-218            [-1, 192, 7, 7]               0\n",
      "          Conv2d-219           [-1, 1152, 7, 7]         221,184\n",
      "     BatchNorm2d-220           [-1, 1152, 7, 7]           2,304\n",
      "            SiLU-221           [-1, 1152, 7, 7]               0\n",
      "          Conv2d-222           [-1, 1152, 7, 7]          28,800\n",
      "     BatchNorm2d-223           [-1, 1152, 7, 7]           2,304\n",
      "            SiLU-224           [-1, 1152, 7, 7]               0\n",
      "AdaptiveAvgPool2d-225           [-1, 1152, 1, 1]               0\n",
      "          Conv2d-226             [-1, 48, 1, 1]          55,344\n",
      "            SiLU-227             [-1, 48, 1, 1]               0\n",
      "          Conv2d-228           [-1, 1152, 1, 1]          56,448\n",
      "         Sigmoid-229           [-1, 1152, 1, 1]               0\n",
      "SqueezeExcitation-230           [-1, 1152, 7, 7]               0\n",
      "          Conv2d-231            [-1, 192, 7, 7]         221,184\n",
      "     BatchNorm2d-232            [-1, 192, 7, 7]             384\n",
      " StochasticDepth-233            [-1, 192, 7, 7]               0\n",
      "          MBConv-234            [-1, 192, 7, 7]               0\n",
      "          Conv2d-235           [-1, 1152, 7, 7]         221,184\n",
      "     BatchNorm2d-236           [-1, 1152, 7, 7]           2,304\n",
      "            SiLU-237           [-1, 1152, 7, 7]               0\n",
      "          Conv2d-238           [-1, 1152, 7, 7]          10,368\n",
      "     BatchNorm2d-239           [-1, 1152, 7, 7]           2,304\n",
      "            SiLU-240           [-1, 1152, 7, 7]               0\n",
      "AdaptiveAvgPool2d-241           [-1, 1152, 1, 1]               0\n",
      "          Conv2d-242             [-1, 48, 1, 1]          55,344\n",
      "            SiLU-243             [-1, 48, 1, 1]               0\n",
      "          Conv2d-244           [-1, 1152, 1, 1]          56,448\n",
      "         Sigmoid-245           [-1, 1152, 1, 1]               0\n",
      "SqueezeExcitation-246           [-1, 1152, 7, 7]               0\n",
      "          Conv2d-247            [-1, 320, 7, 7]         368,640\n",
      "     BatchNorm2d-248            [-1, 320, 7, 7]             640\n",
      "          MBConv-249            [-1, 320, 7, 7]               0\n",
      "          Conv2d-250           [-1, 1280, 7, 7]         409,600\n",
      "     BatchNorm2d-251           [-1, 1280, 7, 7]           2,560\n",
      "            SiLU-252           [-1, 1280, 7, 7]               0\n",
      "AdaptiveAvgPool2d-253           [-1, 1280, 1, 1]               0\n",
      "         Dropout-254                 [-1, 1280]               0\n",
      "          Linear-255                    [-1, 2]           2,562\n",
      "    EfficientNet-256                    [-1, 2]               0\n",
      "================================================================\n",
      "Total params: 4,010,110\n",
      "Trainable params: 4,010,110\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 173.64\n",
      "Params size (MB): 15.30\n",
      "Estimated Total Size (MB): 189.52\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "import torch\n",
    "\n",
    "model = BinaryEfficientNet()\n",
    "summary(model, input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d216868b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 12000\n",
      "Test samples: 2000\n",
      "Classes: ['Blocked', 'Normal']\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define image transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),  # EfficientNet expects 224x224\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Define dataset paths\n",
    "train_dir = \"/Users/emmanuelgeorgep/Desktop/tempp1/Dataset/Train\"\n",
    "test_dir = \"/Users/emmanuelgeorgep/Desktop/tempp1/Dataset/Test\"\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Print dataset info\n",
    "print(\"Train samples:\", len(train_dataset))\n",
    "print(\"Test samples:\", len(test_dataset))\n",
    "print(\"Classes:\", train_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf93c71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, device, epochs=5):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)             \n",
    "            loss = criterion(outputs, labels)     \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        accuracy = correct / total\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] | Loss: {avg_loss:.4f} | Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "661808b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5] | Loss: 0.0683 | Accuracy: 0.9845\n",
      "Epoch [2/5] | Loss: 0.0116 | Accuracy: 0.9965\n",
      "Epoch [2/5] | Loss: 0.0116 | Accuracy: 0.9965\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m      5\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m train_model(model, train_loader, criterion, optimizer, device, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 16\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, criterion, optimizer, device, epochs)\u001b[0m\n\u001b[1;32m     14\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)             \n\u001b[1;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)     \n\u001b[0;32m---> 16\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     19\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    628\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m _engine_run_backward(\n\u001b[1;32m    348\u001b[0m     tensors,\n\u001b[1;32m    349\u001b[0m     grad_tensors_,\n\u001b[1;32m    350\u001b[0m     retain_graph,\n\u001b[1;32m    351\u001b[0m     create_graph,\n\u001b[1;32m    352\u001b[0m     inputs,\n\u001b[1;32m    353\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    354\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    355\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    824\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    825\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = BinaryEfficientNet(pretrained=True)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "train_model(model, train_loader, criterion, optimizer, device, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4583fbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Loss: 0.0295 | Test Accuracy: 0.9880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.029496028589150344, 0.988)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_model(model, test_loader, criterion, device):\n",
    "    model.to(device)\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)             # [B, 2]\n",
    "            loss = criterion(outputs, labels)  # CrossEntropyLoss\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    print(f\"\\nTest Loss: {avg_loss:.4f} | Test Accuracy: {accuracy:.4f}\")\n",
    "    return avg_loss, accuracy\n",
    "    \n",
    "test_model(model, test_loader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31345c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "\n",
    "torch.save(model.state_dict(), \"EfficientNet-KL.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
